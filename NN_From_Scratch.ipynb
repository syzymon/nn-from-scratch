{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J533jbfLc5O-"
   },
   "outputs": [],
   "source": [
    "# Vanilla python + numpy (for speed) = neural network from scratch!\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Stuff for downloading original MNIST dataset: http://yann.lecun.com/exdb/mnist/\n",
    "import urllib.request\n",
    "import gzip\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SSVznKj8gGHg"
   },
   "outputs": [],
   "source": [
    "def download_and_unzip_bytes(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    compressed_file = BytesIO(response.read())\n",
    "    decompressed_file = gzip.GzipFile(fileobj=compressed_file)\n",
    "    return decompressed_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fksBm5kdmdIq"
   },
   "outputs": [],
   "source": [
    "def btos(bytes):\n",
    "    return int.from_bytes(bytes, 'big')\n",
    "\n",
    "def parse_images(img_bytes):\n",
    "    io = BytesIO(img_bytes)\n",
    "    magic = btos(io.read(4))\n",
    "    assert magic == 2051 # magic\n",
    "\n",
    "    n_images = btos(io.read(4))\n",
    "    rows = btos(io.read(4))\n",
    "    cols = btos(io.read(4))\n",
    "    img_sz = rows * cols\n",
    "    \n",
    "    images = np.empty((n_images, img_sz))\n",
    "    for i in range(n_images):\n",
    "        images[i] = np.frombuffer(io.read(img_sz), dtype=np.uint8)\n",
    "    return images\n",
    "\n",
    "def parse_labels(label_bytes):\n",
    "    io = BytesIO(label_bytes)\n",
    "    magic = btos(io.read(4))\n",
    "    assert magic == 2049 # magic\n",
    "\n",
    "    n_labels = btos(io.read(4))\n",
    "    return np.frombuffer(io.read(n_labels), dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVkBBlIWgeES"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(download_and_unzip_bytes, [\n",
    "    'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "    'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "    'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "    'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnv3kKHD17tr"
   },
   "outputs": [],
   "source": [
    "x_train, x_valid = map(parse_images, [x_train, x_valid])\n",
    "y_train, y_valid = map(parse_labels, [y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGtAoYZHxk_9"
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "def show_img(img_vec):\n",
    "    imshow(img_vec.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "2N28XLA3yHJx",
    "outputId": "7a28e27a-5b29-4de3-8c3e-127950ece086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "show_img(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "gTZfS2Co3MyF",
    "outputId": "40753a4c-d860-4101-e45c-cccea35be98a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_valid[0])\n",
    "show_img(x_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgB5bBjh4fFs"
   },
   "outputs": [],
   "source": [
    "def normalize(train, valid):\n",
    "    mn = np.mean(train)\n",
    "    std = np.std(train)\n",
    "    return ((train - mn) / std), ((valid - mn) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Txm4QY6pc9pN"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, inputs, labels):\n",
    "        assert inputs.shape[0] == labels.shape[0]\n",
    "        self._inputs = inputs\n",
    "        self._labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self._inputs[index], self._labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._inputs.shape[0]\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset: Dataset, batch_size: int = 32):\n",
    "        self._ds = dataset\n",
    "        self._batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self._ds), self._batch_size):\n",
    "            yield self._ds[i:i + self._batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tXPsVKG31C7"
   },
   "outputs": [],
   "source": [
    "train_norm, valid_norm = normalize(x_train, x_valid)\n",
    "train = Dataset(train_norm, y_train)\n",
    "valid = Dataset(valid_norm, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x82NsS3VQbYJ"
   },
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    def __init__(self, x):\n",
    "        self.data = x\n",
    "        self.grad = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5XHC7qN3_lt"
   },
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, x):\n",
    "        self._inp = x if isinstance(x, Parameter) else Parameter(x)\n",
    "        self._out = Parameter(self.forward(x.data))\n",
    "        return self._out\n",
    "\n",
    "    def backward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x: np.ndarray):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mz1OXPycCYFN"
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "class CrossEntropy(Module):\n",
    "    def __call__(self, x, targets):\n",
    "        # pdb.set_trace()\n",
    "        self._inp = x if isinstance(x, Parameter) else Parameter(x)\n",
    "        self._softmax = np.exp(self._inp.data) / (np.sum(np.exp(self._inp.data), axis=-1, keepdims=True))\n",
    "        self._winners = self._softmax.argmax(axis=1)\n",
    "        probs = self._softmax[np.arange(len(self._winners)), self._winners]\n",
    "\n",
    "        self._incorrect_ind = (self._winners != targets)\n",
    "        self._out = probs\n",
    "        self._out[self._incorrect_ind] = 1 - self._out[self._incorrect_ind]\n",
    "        self._out = -np.log(self._out)\n",
    "        return self._winners\n",
    "\n",
    "    def backward(self):\n",
    "        # 2 cases - if target OK, just return softmax and -1 in target row\n",
    "        # if target wrong, return softmax in target and softmax - softmax without target (so it is negative)\n",
    "        # First case: correct matches\n",
    "        self._inp.grad = self._softmax\n",
    "        correct_ind = np.logical_not(self._incorrect_ind)\n",
    "        self._inp.grad[correct_ind, self._winners[correct_ind]] -= 1 # Negative loss for good labels\n",
    "\n",
    "        exps_notarget = np.exp(self._inp.data)\n",
    "        exps_notarget[np.arange(len(self._winners)), self._winners] = 0\n",
    "        self._softmax1 = exps_notarget / np.sum(exps_notarget, axis=-1, keepdims=True)\n",
    "\n",
    "        self._softmax1[correct_ind] = 0 # Do not subtract from correct ones\n",
    "        self._inp.grad -= self._softmax1\n",
    "\n",
    "class ReLU(Module):\n",
    "    def forward(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def backward(self):\n",
    "        self._inp.grad = self._out.grad * (self._inp.data > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FiXvUnOpGFo"
   },
   "outputs": [],
   "source": [
    "test_inputs = np.array([\n",
    "  [2, 1],\n",
    "  [3, 7]             \n",
    "])\n",
    "\n",
    "ce = CrossEntropy()\n",
    "out = ce(test_inputs, np.array([1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eMPx_nthpadP",
    "outputId": "66cbd39a-60db-458d-f604-1b5fde5fe0f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dXVt-Y5oNMQE",
    "outputId": "a3fb5efc-60bd-4d72-c169-465a0ef1b362"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73105858, -0.73105858],\n",
       "       [-0.98201379,  0.98201379]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce.backward()\n",
    "ce._inp.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCyh2sT_UZLM"
   },
   "outputs": [],
   "source": [
    "def print_stats(data: np.ndarray):\n",
    "    print(\"Mean:\", data.mean(axis=1), \"Std:\", data.std(axis=1), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4XaX9xsRAU6"
   },
   "outputs": [],
   "source": [
    "class Trainable(Parameter):\n",
    "    def __init__(self, x):\n",
    "        super().__init__(x)\n",
    "\n",
    "class Linear(Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self._n_in = n_in\n",
    "        self._n_out = n_out\n",
    "        self._w = Trainable(self._initialized_weights(n_in, n_out))\n",
    "        self._b = Trainable(np.zeros(n_out))\n",
    "\n",
    "    @staticmethod\n",
    "    def _initialized_weights(n, m):\n",
    "        # TODO: kaiming (or some better) init\n",
    "        return np.random.normal(size=(n, m)) / (2*np.sqrt(m))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self._w.data + self._b.data\n",
    "\n",
    "    def backward(self):\n",
    "        # self._inp.grad = (np.expand_dims(self._w, 1) * self._out.grad[np.newaxis,]).sum(axis=-1)\n",
    "        self._inp.grad = self._out.grad @ self._w.data.T\n",
    "        self._w.grad = (np.expand_dims(self._inp.data.T, 2) * np.expand_dims(self._out.grad, 0)).sum(axis=1)\n",
    "        self._b.grad = self._out.grad.sum(axis=0)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self._w, self._b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJ4s6MBWDQD7"
   },
   "outputs": [],
   "source": [
    "vec = train[0:10][0]\n",
    "lin = Linear(784, 50)\n",
    "relu = ReLU()\n",
    "out = lin(vec)\n",
    "out = relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "U6j_JnbXCwGe",
    "outputId": "77851cd1-343a-4b76-8dfd-027fd1e9bb80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "[0.54019632 0.55717634 0.60519668 0.67980953 0.63125516 0.70740749\n",
      " 0.60219954 0.64161567 0.36145155 0.57281204]\n",
      "Std:\n",
      "[0.80741711 0.88506085 0.82587999 1.0903679  0.93931869 1.12945576\n",
      " 0.9051617  0.93908866 0.60617728 0.84258491]\n"
     ]
    }
   ],
   "source": [
    "print_stats(out.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5o_nA1SmotwM"
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "class Network(Module):\n",
    "    def __init__(self, input_dim = 784, n_out_classes = 10):\n",
    "        self._input_dim = input_dim\n",
    "        self._n_out_classes = n_out_classes\n",
    "        self._layers = [\n",
    "                   Linear(input_dim, 50),\n",
    "                   ReLU(),\n",
    "                   Linear(50, n_out_classes)\n",
    "        ]\n",
    "\n",
    "        self._loss_function = CrossEntropy()\n",
    "\n",
    "    def __call__(self, x, targets):\n",
    "        # pdb.set_trace()\n",
    "        for layer in self._layers:\n",
    "            x = layer(x)\n",
    "        return self._loss_function(x, targets)\n",
    "\n",
    "    def backward(self):\n",
    "        self._loss_function.backward()\n",
    "        for layer in self._layers[::-1]:\n",
    "            layer.backward()\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return list(itertools.chain(*(layer.weights for layer in self._layers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2X1vmlBIPERL"
   },
   "outputs": [],
   "source": [
    "def accuracy(preds, ground_truth):\n",
    "    return np.mean(preds == ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-atari8V8PR"
   },
   "outputs": [],
   "source": [
    "def optimize(param: Trainable, lr=0.002):\n",
    "    param.data -= lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgMXAv7wWLL_"
   },
   "outputs": [],
   "source": [
    "small_ds = Dataset(train_norm, y_train)\n",
    "small_valid = Dataset(valid_norm, y_valid)\n",
    "\n",
    "dl = DataLoader(small_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YDA7Ay6ZFDJ"
   },
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model: Module, dl: DataLoader, valid_set: Dataset):\n",
    "        self._model = model\n",
    "        self._dl = dl\n",
    "        self._valid_set = valid_set\n",
    "    \n",
    "    def fit(self, epochs=1, lr=0.002):\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, batch_y in self._dl:\n",
    "                preds = self._model(batch_x, batch_y)\n",
    "                self._model.backward()\n",
    "\n",
    "                for weight in self._model.weights:\n",
    "                    optimize(weight, lr)\n",
    "\n",
    "            valid_preds = self._model(*self._valid_set[:])\n",
    "            print(f\"Epoch: {epoch}, Accuracy: {accuracy(valid_preds, self._valid_set[:][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szXAQP2hbnUv"
   },
   "outputs": [],
   "source": [
    "learn = Learner(Network(), dl, small_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "DlhWEVxccuba",
    "outputId": "3c051a19-5d2b-4c21-cbfe-4ba002ebfca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Accuracy: 0.9346\n",
      "Epoch: 1, Accuracy: 0.9497\n",
      "Epoch: 2, Accuracy: 0.9569\n",
      "CPU times: user 3min 27s, sys: 3min 16s, total: 6min 44s\n",
      "Wall time: 34.6 s\n"
     ]
    }
   ],
   "source": [
    "%time learn.fit(epochs=3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NN_From_Scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
